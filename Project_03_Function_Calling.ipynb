{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIRHHavMxcCMxGIirl7AV1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fariha-Asif/Quarter-2-projects-PIAIC/blob/main/Project_03_Function_Calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Function_calling**"
      ],
      "metadata": {
        "id": "UHdu1t635RlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Google Generative AI Library"
      ],
      "metadata": {
        "id": "aMylfO855foK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q \"google-generativeai>=0.7.2\""
      ],
      "metadata": {
        "id": "KTiofUWe5l9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Necessary Modules\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Configure Google Generative AI API\n",
        "genai.configure(api_key=userdata.get(\"GOOGLE_API_KEY\"))"
      ],
      "metadata": {
        "id": "whV--syD5v37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up a model with tools"
      ],
      "metadata": {
        "id": "x4bddEb25yzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def turn_on_uv_lights():\n",
        "    \"\"\"Turn on the uv lighting system.\"\"\"\n",
        "    print(\"LIGHTBOT: UV lights enabled.\")\n",
        "\n",
        "def turn_on_light():\n",
        "    \"\"\"Turn on the lighting system.\"\"\"\n",
        "    print(\"LIGHTBOT: Lights enabled.\")\n",
        "\n",
        "\n",
        "def change_light_color(rgb_hex: str):\n",
        "    \"\"\"Set the light color. Lights must be enabled for this to work.\"\"\"\n",
        "    print(f\"LIGHTBOT: Lights set to {rgb_hex}.\")\n",
        "\n",
        "\n",
        "def turn_off_lights():\n",
        "    \"\"\"Stop flashing lights.\"\"\"\n",
        "    print(\"LIGHTBOT: Lights turned off.\")\n",
        "\n",
        "\n",
        "light_controls = [turn_on_uv_lights, turn_on_light, change_light_color, turn_off_lights]\n",
        "instruction = \"You are a helpful lighting system bot. You can turn lights on and off, and you can set the color. Do not perform any other tasks.\"\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    \"models/gemini-1.5-pro\", tools=light_controls, system_instruction=instruction\n",
        ")\n",
        "\n",
        "chat = model.start_chat()"
      ],
      "metadata": {
        "id": "cuGp1PKv5247"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a helper function for setting function_calling_config on tool_config."
      ],
      "metadata": {
        "id": "ODTke2vw5_2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.generativeai.types import content_types\n",
        "from collections.abc import Iterable\n",
        "\n",
        "\n",
        "def tool_config_from_mode(mode: str, fns: Iterable[str] = ()):\n",
        "    \"\"\"Create a tool config with the specified function calling mode.\"\"\"\n",
        "    return content_types.to_tool_config(\n",
        "        {\"function_calling_config\": {\"mode\": mode, \"allowed_function_names\": fns}}\n",
        "    )"
      ],
      "metadata": {
        "id": "-E2WpOqt6A7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text-only mode: NONE"
      ],
      "metadata": {
        "id": "2mttpgod6Gka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have provided the model with tools, but do not want to use those tools for the current conversational turn, then specify NONE as the mode. NONE tells the model not to make any function calls, and will behave as though none have been provided."
      ],
      "metadata": {
        "id": "yFjNsxJ46J9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tool_config = tool_config_from_mode(\"none\")\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"Hello light-bot, what can you do?\", tool_config=tool_config\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "q63K5q6s6NjS",
        "outputId": "d0dee9b0-4573-4a41-d44c-c4200fa5a1c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I can turn lights on and off, and I can set the color of the lights.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automatic mode: AUTO"
      ],
      "metadata": {
        "id": "NbnLbBk66XlN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To allow the model to decide whether to respond in text or call specific functions, you can specify AUTO as the mode."
      ],
      "metadata": {
        "id": "P76qc54C6atc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tool_config = tool_config_from_mode(\"auto\")\n",
        "\n",
        "response = chat.send_message(\"Turn on the UV lights!\", tool_config=tool_config)\n",
        "print(response.parts[0])\n",
        "chat.rewind();  # You are not actually calling the function, so remove this from the history."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "gsfpHpk36ckj",
        "outputId": "9222df85-5562-46c8-db9a-ae63f63b1985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "function_call {\n",
            "  name: \"turn_on_uv_lights\"\n",
            "  args {\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function-calling mode: ANY"
      ],
      "metadata": {
        "id": "wOFvs6bH6jLi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting the mode to ANY will force the model to make a function call. By setting allowed_function_names, the model will only choose from those functions. If it is not set, all of the functions in tools are candidates for function calling.\n",
        "\n",
        "In this example system, if the lights are already on, then the user can change color or turn the lights off."
      ],
      "metadata": {
        "id": "V2amp7AF6kxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "available_fns = [\"change_light_color\", \"turn_off_lights\"]\n",
        "\n",
        "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
        "\n",
        "response = chat.send_message(\"Make this place Orange!\", tool_config=tool_config)\n",
        "print(response.parts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "JZrm5wQm6nQD",
        "outputId": "70c82e8a-908d-45d7-c869-d56c9f3a9003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "function_call {\n",
            "  name: \"change_light_color\"\n",
            "  args {\n",
            "    fields {\n",
            "      key: \"rgb_hex\"\n",
            "      value {\n",
            "        string_value: \"FF4500\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automatic function calling"
      ],
      "metadata": {
        "id": "s9JPoqOF6s9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tool_config works when enabling automatic function calling too."
      ],
      "metadata": {
        "id": "TEG3Tesr6usj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "available_fns = [\"turn_on_light\"]\n",
        "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
        "\n",
        "auto_chat = model.start_chat(enable_automatic_function_calling=True)\n",
        "#auto_chat.send_message(\"It's awful dark in here...\", tool_config=tool_config)\n",
        "auto_chat.send_message(\"Set light color in yellow...\", tool_config=tool_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "HJh0D8OZ6xiq",
        "outputId": "8f6f1169-0603-4017-c7fe-6475f21b3cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LIGHTBOT: Lights enabled.\n",
            "LIGHTBOT: Lights set to #FFFF00.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "response:\n",
              "GenerateContentResponse(\n",
              "    done=True,\n",
              "    iterator=None,\n",
              "    result=protos.GenerateContentResponse({\n",
              "      \"candidates\": [\n",
              "        {\n",
              "          \"content\": {\n",
              "            \"parts\": [\n",
              "              {\n",
              "                \"text\": \"The light color has been set to yellow. anything else?\"\n",
              "              }\n",
              "            ],\n",
              "            \"role\": \"model\"\n",
              "          },\n",
              "          \"finish_reason\": \"STOP\",\n",
              "          \"avg_logprobs\": -0.126002828280131\n",
              "        }\n",
              "      ],\n",
              "      \"usage_metadata\": {\n",
              "        \"prompt_token_count\": 246,\n",
              "        \"candidates_token_count\": 12,\n",
              "        \"total_token_count\": 258\n",
              "      }\n",
              "    }),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def power_disco_ball(power: bool) -> bool:\n",
        "    \"\"\"Powers the spinning disco ball.\"\"\"\n",
        "    print(f\"Disco ball is {'spinning!' if power else 'stopped.'}\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def start_music(energetic: bool, loud: bool, bpm: int) -> str:\n",
        "    \"\"\"Play some music matching the specified parameters.\n",
        "\n",
        "    Args:\n",
        "      energetic: Whether the music is energetic or not.\n",
        "      loud: Whether the music is loud or not.\n",
        "      bpm: The beats per minute of the music.\n",
        "\n",
        "    Returns: The name of the song being played.\n",
        "    \"\"\"\n",
        "    print(f\"Starting music! {energetic=} {loud=}, {bpm=}\")\n",
        "    return \"Never gonna give you up.\"\n",
        "\n",
        "\n",
        "def dim_lights(brightness: float) -> bool:\n",
        "    \"\"\"Dim the lights.\n",
        "\n",
        "    Args:\n",
        "      brightness: The brightness of the lights, 0.0 is off, 1.0 is full.\n",
        "    \"\"\"\n",
        "    print(f\"Lights are now set to {brightness:.0%}\")\n",
        "    return True"
      ],
      "metadata": {
        "id": "KeK_oLb565sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model up with tools.\n",
        "house_fns = [power_disco_ball, start_music, dim_lights]\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\", tools=house_fns)\n",
        "\n",
        "# Call the API.\n",
        "chat = model.start_chat()\n",
        "response = chat.send_message(\"Turn this place into a party !\")\n",
        "\n",
        "# Print out each of the function calls requested from this single call.\n",
        "for part in response.parts:\n",
        "    if fn := part.function_call:\n",
        "        args = \", \".join(f\"{key}={val}\" for key, val in fn.args.items())\n",
        "        print(f\"{fn.name}({args})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "R3dd-PSH69SC",
        "outputId": "81c75dc3-dd48-4c5f-da70-995ebc1c0360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "power_disco_ball(power=True)\n",
            "start_music(loud=True, energetic=True, bpm=120.0)\n",
            "dim_lights(brightness=0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate the responses from the specified tools.\n",
        "responses = {\n",
        "    \"power_disco_ball\": True,\n",
        "    \"start_music\": \"Never gonna give you up.\",\n",
        "    \"dim_lights\": True,\n",
        "}\n",
        "\n",
        "# Build the response parts.\n",
        "response_parts = [\n",
        "    genai.protos.Part(function_response=genai.protos.FunctionResponse(name=fn, response={\"result\": val}))\n",
        "    for fn, val in responses.items()\n",
        "]\n",
        "\n",
        "response = chat.send_message(response_parts)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "hqz1OnVY7B9S",
        "outputId": "fefeb4a8-1124-4a81-b7d6-ed683ef23f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Party started!  Playing \"Never gonna give you up\" at 120 bpm. The disco ball is on and the lights are dimmed to 50% brightness.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def multiply(a:float, b:float):\n",
        "    \"\"\"returns a * b.\"\"\"\n",
        "    return a*b\n",
        "\n",
        "model = genai.GenerativeModel(model_name='gemini-1.5-flash',\n",
        "                             tools=[multiply])\n",
        "\n",
        "model._tools.to_proto()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJP8sMKu7C_6",
        "outputId": "01ed565d-952a-466f-b034-6e2104716ee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[function_declarations {\n",
              "   name: \"multiply\"\n",
              "   description: \"returns a * b.\"\n",
              "   parameters {\n",
              "     type_: OBJECT\n",
              "     properties {\n",
              "       key: \"b\"\n",
              "       value {\n",
              "         type_: NUMBER\n",
              "       }\n",
              "     }\n",
              "     properties {\n",
              "       key: \"a\"\n",
              "       value {\n",
              "         type_: NUMBER\n",
              "       }\n",
              "     }\n",
              "     required: \"a\"\n",
              "     required: \"b\"\n",
              "   }\n",
              " }]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task"
      ],
      "metadata": {
        "id": "JmQyPUtk7Ier"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: make a list of dictionary , key samples is 10 samples of person, which include name, father name , education and address..\n",
        "\n",
        "import random\n",
        "\n",
        "def generate_person_data():\n",
        "  names = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\", \"Jona\", \"Alex\", \"Ema\", \"Sophia\", \"William\"]\n",
        "  father_names = [\"Robert\", \"Michael\", \"James\", \"John\", \"David\", \"Richard\", \"Joseph\", \"Thomas\", \"Charles\", \"Christopher\"]\n",
        "  educations = [\"High School\", \"Bachelor's\", \"Master's\", \"PhD\", \"Associate's\"]\n",
        "  addresses = [\"123 Main St\", \"456 Oak Ave\", \"789 Pine Ln\", \"1011 Elm St\", \"1213 Maple Dr\"]\n",
        "\n",
        "  name = random.choice(names)\n",
        "  father_name = random.choice(father_names)\n",
        "  education = random.choice(educations)\n",
        "  address = random.choice(addresses)\n",
        "  return {\n",
        "      \"name\": name,\n",
        "      \"father_name\": father_name,\n",
        "      \"education\": education,\n",
        "      \"address\": address\n",
        "  }\n",
        "\n",
        "\n",
        "samples = []\n",
        "for _ in range(10):\n",
        "  samples.append(generate_person_data())\n",
        "\n",
        "samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfEWCBRx7JyM",
        "outputId": "169f3e11-ec9e-4ed1-eb9c-b98258789bf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'Charlie',\n",
              "  'father_name': 'Thomas',\n",
              "  'education': \"Master's\",\n",
              "  'address': '789 Pine Ln'},\n",
              " {'name': 'Sophia',\n",
              "  'father_name': 'Charles',\n",
              "  'education': 'High School',\n",
              "  'address': '1213 Maple Dr'},\n",
              " {'name': 'Bob',\n",
              "  'father_name': 'Michael',\n",
              "  'education': 'High School',\n",
              "  'address': '1213 Maple Dr'},\n",
              " {'name': 'Ema',\n",
              "  'father_name': 'Thomas',\n",
              "  'education': 'High School',\n",
              "  'address': '789 Pine Ln'},\n",
              " {'name': 'Alice',\n",
              "  'father_name': 'Michael',\n",
              "  'education': 'High School',\n",
              "  'address': '1213 Maple Dr'},\n",
              " {'name': 'Sophia',\n",
              "  'father_name': 'Charles',\n",
              "  'education': \"Associate's\",\n",
              "  'address': '1011 Elm St'},\n",
              " {'name': 'Alex',\n",
              "  'father_name': 'Charles',\n",
              "  'education': \"Master's\",\n",
              "  'address': '1213 Maple Dr'},\n",
              " {'name': 'Sophia',\n",
              "  'father_name': 'James',\n",
              "  'education': 'PhD',\n",
              "  'address': '789 Pine Ln'},\n",
              " {'name': 'Bob',\n",
              "  'father_name': 'Thomas',\n",
              "  'education': \"Bachelor's\",\n",
              "  'address': '123 Main St'},\n",
              " {'name': 'Charlie',\n",
              "  'father_name': 'James',\n",
              "  'education': 'PhD',\n",
              "  'address': '123 Main St'}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Make a function with above list when we ask name as a input, it will give information to that person.\n",
        "\n",
        "def get_person_info(name):\n",
        "    for person in samples:\n",
        "        if person[\"name\"] == name:\n",
        "            return person\n",
        "    return \"No information found for that person.\"\n",
        "\n",
        "# Example usage\n",
        "person_name = input(\"Enter the name of the person: \")\n",
        "info = get_person_info(person_name)\n",
        "info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fdZaReb7SkK",
        "outputId": "9e4cd2f8-d50e-43c8-a62e-dd41a4e09b5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the name of the person: Alice\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Alice',\n",
              " 'father_name': 'Michael',\n",
              " 'education': 'High School',\n",
              " 'address': '1213 Maple Dr'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task with LLM"
      ],
      "metadata": {
        "id": "2lO0SLhQ8ROs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: make a list of dictionary , key samples is 10 samples of person, which include name, father name , education and address.. include LLM in it\n",
        "\n",
        "import random\n",
        "\n",
        "def generate_person_data():\n",
        "    names = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\", \"Jona\", \"Sophia\", \"William\", \"Olivia\", \"James\"]\n",
        "    father_names = [\"Robert\", \"Michael\", \"William\", \"David\", \"Richard\", \"Joseph\", \"Thomas\", \"Charles\", \"Christopher\", \"Daniel\"]\n",
        "    educations = [\"High School\", \"Bachelor's Degree\", \"Master's Degree\", \"PhD\", \"Associate's Degree\"]\n",
        "    addresses = [\"123 Main St\", \"456 Oak Ave\", \"789 Pine Ln\", \"1011 Elm St\", \"1213 Maple Dr\"]\n",
        "\n",
        "    name = random.choice(names)\n",
        "    father_name = random.choice(father_names)\n",
        "    education = random.choice(educations)\n",
        "    address = random.choice(addresses)\n",
        "\n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"father_name\": father_name,\n",
        "        \"education\": education,\n",
        "        \"address\": address,\n",
        "    }\n",
        "\n",
        "samples = []\n",
        "for _ in range(10):\n",
        "    samples.append(generate_person_data())\n",
        "\n",
        "samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxCnAZXS8VRl",
        "outputId": "4b248891-d2d8-44df-eda6-a1c9f6294f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'Olivia',\n",
              "  'father_name': 'Robert',\n",
              "  'education': \"Bachelor's Degree\",\n",
              "  'address': '123 Main St'},\n",
              " {'name': 'Jona',\n",
              "  'father_name': 'David',\n",
              "  'education': 'High School',\n",
              "  'address': '789 Pine Ln'},\n",
              " {'name': 'William',\n",
              "  'father_name': 'Charles',\n",
              "  'education': 'High School',\n",
              "  'address': '1011 Elm St'},\n",
              " {'name': 'Jona',\n",
              "  'father_name': 'Thomas',\n",
              "  'education': 'High School',\n",
              "  'address': '1011 Elm St'},\n",
              " {'name': 'Charlie',\n",
              "  'father_name': 'Charles',\n",
              "  'education': 'PhD',\n",
              "  'address': '123 Main St'},\n",
              " {'name': 'Bob',\n",
              "  'father_name': 'Joseph',\n",
              "  'education': \"Associate's Degree\",\n",
              "  'address': '789 Pine Ln'},\n",
              " {'name': 'Sophia',\n",
              "  'father_name': 'Charles',\n",
              "  'education': 'PhD',\n",
              "  'address': '1011 Elm St'},\n",
              " {'name': 'Bob',\n",
              "  'father_name': 'Michael',\n",
              "  'education': 'High School',\n",
              "  'address': '1213 Maple Dr'},\n",
              " {'name': 'Jona',\n",
              "  'father_name': 'Michael',\n",
              "  'education': \"Associate's Degree\",\n",
              "  'address': '1213 Maple Dr'},\n",
              " {'name': 'David',\n",
              "  'father_name': 'Robert',\n",
              "  'education': 'PhD',\n",
              "  'address': '1213 Maple Dr'}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Make a function with above list when we ask name as a input, it will give information to that person and recheck by LLM with last cell\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def get_person_info(name, samples):\n",
        "  \"\"\"\n",
        "  Retrieves information about a person from a list of dictionaries.\n",
        "\n",
        "  Args:\n",
        "    name: The name of the person to search for.\n",
        "    samples: A list of dictionaries, where each dictionary represents a person and\n",
        "             contains keys like \"name\", \"father_name\", \"education\", and \"address\".\n",
        "\n",
        "  Returns:\n",
        "    A dictionary containing the person's information if found, otherwise None.\n",
        "  \"\"\"\n",
        "  for person in samples:\n",
        "    if person[\"name\"] == name:\n",
        "      return person\n",
        "  return None\n",
        "\n",
        "def verify_with_llm(person_info):\n",
        "  \"\"\"\n",
        "  Verifies the person's information using a large language model.\n",
        "\n",
        "  Args:\n",
        "    person_info: A dictionary containing the person's information.\n",
        "\n",
        "  Returns:\n",
        "    A string representing the LLM's verification.\n",
        "  \"\"\"\n",
        "\n",
        "  # Construct prompt for LLM based on person's information\n",
        "  prompt = f\"\"\"Verify the following information:\\nName: {person_info['name']}\\nFather's Name: {person_info['father_name']}\\nEducation: {person_info['education']}\\nAddress: {person_info['address']}\n",
        "  \\nIs this information likely to be correct?  Respond with 'Correct' or 'Incorrect' only\"\"\"\n",
        "\n",
        "  # Replace with actual LLM call using the google.generativeai library\n",
        "  # The following is a placeholder; uncomment and modify as needed\n",
        "  # response = genai.generate_text(prompt=prompt, model='models/gemini-pro')\n",
        "  # verification_result = response.result\n",
        "\n",
        "  # Placeholder result (replace with actual LLM response)\n",
        "  verification_result = \"Correct\" # Example: Replace with actual LLM output\n",
        "\n",
        "  return verification_result\n",
        "\n",
        "# Example usage\n",
        "name_to_find = input(\"Enter the name: \")\n",
        "person_info = get_person_info(name_to_find, samples)\n",
        "\n",
        "if person_info:\n",
        "  print(f\"Information for {name_to_find}:\")\n",
        "  print(person_info)\n",
        "\n",
        "  verification = verify_with_llm(person_info)\n",
        "  print(f\"\\nLLM Verification: {verification}\")\n",
        "\n",
        "else:\n",
        "  print(f\"No information found for {name_to_find}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8CYsPO48a-i",
        "outputId": "2c31cdcb-07a9-43e9-a90c-2135be2647b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the name: Bob\n",
            "Information for Bob:\n",
            "{'name': 'Bob', 'father_name': 'Joseph', 'education': \"Associate's Degree\", 'address': '789 Pine Ln'}\n",
            "\n",
            "LLM Verification: Correct\n"
          ]
        }
      ]
    }
  ]
}